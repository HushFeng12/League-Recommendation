# -*- coding: utf-8 -*-
"""league recommendation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FEboOK5XGqHAC50Sq7VpfXcAYEkffqdo
"""

import pandas as pd
import numpy as np
from itertools import combinations,product
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestClassifier
import ast
import warnings
from sklearn.exceptions import DataConversionWarning
warnings.filterwarnings(action='ignore', category=UserWarning)

# df = pd.read_csv('match_info.csv', encoding='iso-8859-1')
# df.head()

def data_transform(df):
  col_name = ['Top','Jungle','Middle','Carry','Utility',\
              'Top2','Jungle2','Middle2','Carry2','Utility2',\
              'Top_Damage','Jungle_Damage','Middle_Damage','Carry_Damage','Utility_Damage',\
              'Top_FirstBlood','Jungle_FirstBlood','Middle_FirstBlood','Carry_FirstBlood','Utility_FirstBlood',\
              'Top_FirstTower','Jungle_FirstTower','Middle_FirstTower','Carry_FirstTower','Utility_FirstTower',\
              'Top_Wards','Jungle_Wards','Middle_Wards','Carry_Wards','Utility_Wards',\
              'Top_CC','Jungle_CC','Middle_CC','Carry_CC','Utility_CC',\
              'Win']
  out = []
  for index,row in df.iterrows():
    temp = []

    name = ast.literal_eval(row['championName'])
    time = ast.literal_eval(row['timePlayed'])[0]

    damage = ast.literal_eval(row['totalDamageDealt'])
    firstblood = ast.literal_eval(row['firstBloodKill'])
    firsttower = ast.literal_eval(row['firstTowerKill'])
    wards = ast.literal_eval(row['wardsPlaced'])
    timeCC = ast.literal_eval(row['timeCCingOthers'])
    win = ast.literal_eval(row['win'])

    temp += name

    temp.extend([60*i/time for i in damage[:5]])
    temp.extend([int(i) for i in firstblood[:5]])
    temp.extend([int(i) for i in firsttower[:5]])
    temp.extend([60*i/time for i in wards[:5]])
    temp.extend([60*i/time for i in timeCC[:5]])
    temp.append(win[0])
    out.append(temp)

    temp = []
    temp += name[5:]
    temp += name[:5]
    temp.extend([60*i/time for i in damage[5:]])
    temp.extend([int(i) for i in firstblood[5:]])
    temp.extend([int(i) for i in firsttower[5:]])
    temp.extend([60*i/time for i in wards[5:]])
    temp.extend([60*i/time for i in timeCC[5:]])
    temp.append(win[6])
    out.append(temp)

  result = pd.DataFrame(out,columns=col_name)
  return result

dataframes = []
files = ['match_info_BRONZEIV','match_info_IRONIII','match_info_IRONIV']
for file in files:
  df = pd.read_csv(f'{file}.csv', encoding='iso-8859-1')
  dataframes.append(data_transform(df))

dff = pd.concat(dataframes, ignore_index=True)

dff.head()

positions = ['Top']
metrics = ['_Damage','_FirstBlood','_FirstTower','_Wards', '_CC']
pos = [i+j for i in positions for j in metrics]
X, y = dff[pos], dff['Win']
rf = RandomForestClassifier(random_state=42).fit(X, y)

importances = rf.feature_importances_
importances_series = pd.Series(importances,index=metrics).sort_values(ascending=False)

top_contributors = [i[1:] for i in importances_series[:3].index]
top_contributors

def handle_nan(value):
  if np.isnan(value):
      return 0
  return value

def rf_calculator(dff, positions):
    if type(positions)==str:
      positions = [positions]
    metrics = ['_Damage','_FirstBlood','_FirstTower','_Wards', '_CC']
    pos = [i+j for i in positions for j in metrics]
    X, y = dff[pos], dff['Win']
    rf = RandomForestClassifier(random_state=42).fit(X, y)

    importances = rf.feature_importances_
    importances_series = pd.Series(importances,index=metrics).sort_values(ascending=False)
    top_contributors = [i[1:] for i in importances_series[:3].index]

    return rf,top_contributors

def combo(df,opponent,opp_position,positions):
  result = []

  #filter by the given opponent and combine all the champions that appeared in the records
  #we want to find winners among winners, so all the record searching process are constrained with victory against the given oppnent
  df_filtered = df[(df[opp_position+'2']==opponent) & (df['Win']==True)]
  combinations = product(*[df_filtered[i].unique() for i in positions])
  total = np.prod([len(df_filtered[i].unique()) for i in positions])

  #specify the domain of metrics that are utilzed in this model
  constraint = [5,3]
  metrics = ['_Damage','_FirstBlood','_FirstTower','_Wards', '_CC']

  #obtain the random forest model for each position
  rfs, top_kpi = [],[]
  for i in positions:
    rfs.append(rf_calculator(df,[i])[0])
    top_kpi.append(rf_calculator(df,[i])[1])

  for ind,combination in enumerate(combinations):

    skip = 0
    #check duplicate in opponent
    for cham in set(combination):
      if cham in opponent:
        skip = 1
        break

    if skip:
      # print('{:.2%}'.format(ind/total))
      continue

    #check duplicate in combination
    if len(combination)!=len(set(combination)):
      skip = 1
      continue

    #calculate the individual scores

    individual = []
    for i,champ in enumerate(combination):
      #filter the champ
      temp = df_filtered[df_filtered[positions[i]]==champ]

      if temp.empty or len(temp)<constraint[0]:
        skip = 1
        break
          # raise ValueError(f"Empty DataFrame after filtering for {positions[i]}=={champ}")

      if skip:
        # print('{:.2%}'.format(ind/total))
        continue

      base_X = []

      #get all the Xs and calculate the winning rate
      for j in metrics:
        base_X.append(handle_nan(temp[f'{positions[i]}'+j].mean()))

      base_X_df = pd.DataFrame([base_X], columns=[f'{positions[i]}'+j for j in metrics])
      prob = rfs[i].predict_proba(base_X_df)
      individual.append(prob[0][1])

    #calculate the scores in combinations

    temp = df_filtered.copy()
    comb = []

    #filter champs in the combination
    for i, champ in enumerate(combination):
      temp = temp[temp[positions[i]]==champ]
      if temp.empty or len(temp)<constraint[1]:
        skip = 1
        break
          # raise ValueError(f"Empty DataFrame after filtering for {positions[i]}=={champ}")

    if skip:
      # print('{:.2%}'.format(ind/total))
      continue

    #get all the Xs and calculate the winning rates
    Xs = []
    for i in range(len(combination)):
      X = []
      for j in metrics:
        X.append(handle_nan(temp[f'{positions[i]}'+j].mean()))
      X_df = pd.DataFrame([X], columns=[f'{positions[i]}'+j for j in metrics])
      Xs.append(X_df)
      prob = rfs[i].predict_proba(X_df)
      comb.append(prob[0][1])

    #test Pareto efficiency for all the combinations and keep the efficient sets with their scores
    if np.array([i>=j for i,j in zip(comb,individual)]).all() and np.array([i>j for i,j in zip(comb,individual)]).any():
      result.append({position: champion for position, champion in zip(positions, combination)})
      for index,pos in enumerate(positions):
        result[-1][pos+' Score'] = comb[index]

      #performances in top 3 contributors by the random forest model
      for index,pos in enumerate(positions):
        for j in range(3):
          result[-1][pos+' '+top_kpi[index][j]] = round(Xs[index][f'{pos}_'+ top_kpi[index][j]][0])

    # print('{:2%}'.format(ind/total), end='\r', flush=True)
    # print('{:.2%}'.format(ind/total))


  if not result:
    raise ValueError("Not Available to Generate Combinations based on Current Dataset")

  #using scores to further streamline the combination list
  r = pd.DataFrame(result)
  #get the ranks for each score and then average
  for index,pos in enumerate(positions):
    r[f'rank {index+1}'] = r[pos+' Score'].rank(ascending=False)
  r['Average Rank'] = (r['rank 1'] + r['rank 2']) / 2

  #switch the position for better look
  for index,i in enumerate(['rank 1','rank 2','Average Rank']):
    temp = r.pop(i)
    r.insert(index+4,i,temp)

  r_sorted = r.sort_values('Average Rank')

  #return the combinations with top 50% average rank in all list, #rows in [1,10]
  return r_sorted[:max(min(10,int(len(r_sorted)/2)),1)]

combo(dff,'Jinx','Carry',['Carry','Utility'])

'''
BEST COMBOS = [[AB], [BC], .....]
BEST COUNTERS = [[AB], [CA], ....]
FIND THE COMMON GROUND BETWEEN THESE TWO
HERE ARE OUR RECOMMENDATION [[AB], ...]

BEST COMBO HYPOTHESIS TESTING:
  MEAN (A2 + B2) > MEAN (A2) + MEAN (B2)

KPI: Logistic Regression

'''

